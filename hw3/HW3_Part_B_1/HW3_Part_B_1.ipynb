{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3 - Part B.1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JAHMTjF8u8z"
      },
      "source": [
        "import numpy as np\n",
        "def generate_non_linear_three_input_two_output(number_of_rows, dimensions, weights_0, bias_0, weights_1, bias_1):\n",
        "\n",
        "  n = number_of_rows\n",
        "  d = dimensions\n",
        "\n",
        "  # Generate numbers between -1.0 and 1.0, n rows and 3 columns\n",
        "  x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "  # Showing 20 of them\n",
        "  # print(x[:10])\n",
        "\n",
        "  # y = w * x + b\n",
        "  # y = (w_0 * x_0) + (w_1 * x_1) + (w_2 * x_2)\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_0 = np.array([weights_0]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_0 = np.array(bias_0)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_0 = ((x ** 2) @ weights_true_0) + (x @ weights_true_0) + bias_true_0\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_0.shape}, bias: {bias_true_0.shape}, y: {y_true_0.shape}')\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_1 = np.array([weights_1]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_1 = np.array(bias_1)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_1 = ((x ** 2) @ weights_true_1) + (x @ weights_true_1) + bias_true_1\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_1.shape}, bias: {bias_true_1.shape}, y: {y_true_1.shape}')\n",
        "\n",
        "  return { \"input\" : x, \"weights_true_0\" : weights_true_0, \"bias_true_0\" : bias_true_0, \"y_true_0\" : y_true_0, \"weights_true_1\" : weights_true_1, \"bias_true_1\" : bias_true_1, \"y_true_1\" : y_true_1}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWe5lNUn-3kD",
        "outputId": "d4c9922a-7bdf-4afb-b471-c713e675c8b9"
      },
      "source": [
        "three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtKXgKRN-6gE"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifotd-uU-8cL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TorchModel(nn.Module):\n",
        "  def __init__(self, input_dim, num_hidden):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, num_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(num_hidden, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    l1 = self.linear1(x)\n",
        "    r = self.relu(l1)\n",
        "    l2 = self.linear2(r)\n",
        "    return l2\n",
        "  \n",
        "x = three_input_two_output_func['input']\n",
        "y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_0']).float()]\n",
        "d = 3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRgx7RLTVl1I",
        "outputId": "7fd665d1-ee52-4222-8b00-6dbdb19a8c35"
      },
      "source": [
        "# Now we run the training loop\n",
        "from typing import Any, Callable\n",
        "\n",
        "def torch_fit():\n",
        "  \n",
        "  three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])\n",
        "  x = torch.tensor(three_input_two_output_func['input']).float()\n",
        "  y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_1']).float()]\n",
        "  d = 3\n",
        "  \n",
        "  lr = 0.1\n",
        "  num_epochs = 40\n",
        "  \n",
        "  loss_0 = nn.MSELoss()\n",
        "  model_0 = TorchModel(d, 10)\n",
        "\n",
        "  loss_1 = nn.MSELoss()\n",
        "  model_1 = TorchModel(d, 10)\n",
        "\n",
        "  optimizer_0 = torch.optim.SGD(model_0.parameters(), lr=lr)\n",
        "  optimizer_1 = torch.optim.SGD(model_1.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    optimizer_0.zero_grad()\n",
        "    optimizer_1.zero_grad()\n",
        "    \n",
        "    y_pred_tensor_0 = model_0(x)\n",
        "    y_pred_tensor_1 = model_1(x)\n",
        "\n",
        "    loss_value_0 = loss_0(y_pred_tensor_0, y_true_0_1[0])\n",
        "    loss_value_1 = loss_1(y_pred_tensor_1, y_true_0_1[1])\n",
        "\n",
        "    print(loss_value_0, loss_value_1)\n",
        "\n",
        "    loss_value_0.backward()\n",
        "    loss_value_1.backward()\n",
        "\n",
        "    optimizer_0.step()\n",
        "    optimizer_1.step()\n",
        "\n",
        "torch_fit()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "tensor(5.9079, grad_fn=<MseLossBackward>) tensor(8.7523, grad_fn=<MseLossBackward>)\n",
            "tensor(5.3769, grad_fn=<MseLossBackward>) tensor(6.4882, grad_fn=<MseLossBackward>)\n",
            "tensor(4.9248, grad_fn=<MseLossBackward>) tensor(5.3669, grad_fn=<MseLossBackward>)\n",
            "tensor(4.4438, grad_fn=<MseLossBackward>) tensor(4.5897, grad_fn=<MseLossBackward>)\n",
            "tensor(3.9066, grad_fn=<MseLossBackward>) tensor(3.9482, grad_fn=<MseLossBackward>)\n",
            "tensor(3.3339, grad_fn=<MseLossBackward>) tensor(3.3731, grad_fn=<MseLossBackward>)\n",
            "tensor(2.7661, grad_fn=<MseLossBackward>) tensor(2.8384, grad_fn=<MseLossBackward>)\n",
            "tensor(2.2568, grad_fn=<MseLossBackward>) tensor(2.3444, grad_fn=<MseLossBackward>)\n",
            "tensor(1.8467, grad_fn=<MseLossBackward>) tensor(1.9056, grad_fn=<MseLossBackward>)\n",
            "tensor(1.5565, grad_fn=<MseLossBackward>) tensor(1.5393, grad_fn=<MseLossBackward>)\n",
            "tensor(1.3721, grad_fn=<MseLossBackward>) tensor(1.2531, grad_fn=<MseLossBackward>)\n",
            "tensor(1.2621, grad_fn=<MseLossBackward>) tensor(1.0463, grad_fn=<MseLossBackward>)\n",
            "tensor(1.1977, grad_fn=<MseLossBackward>) tensor(0.9069, grad_fn=<MseLossBackward>)\n",
            "tensor(1.1575, grad_fn=<MseLossBackward>) tensor(0.8163, grad_fn=<MseLossBackward>)\n",
            "tensor(1.1272, grad_fn=<MseLossBackward>) tensor(0.7570, grad_fn=<MseLossBackward>)\n",
            "tensor(1.1008, grad_fn=<MseLossBackward>) tensor(0.7170, grad_fn=<MseLossBackward>)\n",
            "tensor(1.0730, grad_fn=<MseLossBackward>) tensor(0.6882, grad_fn=<MseLossBackward>)\n",
            "tensor(1.0405, grad_fn=<MseLossBackward>) tensor(0.6656, grad_fn=<MseLossBackward>)\n",
            "tensor(1.0072, grad_fn=<MseLossBackward>) tensor(0.6470, grad_fn=<MseLossBackward>)\n",
            "tensor(0.9734, grad_fn=<MseLossBackward>) tensor(0.6301, grad_fn=<MseLossBackward>)\n",
            "tensor(0.9398, grad_fn=<MseLossBackward>) tensor(0.6143, grad_fn=<MseLossBackward>)\n",
            "tensor(0.9024, grad_fn=<MseLossBackward>) tensor(0.6006, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8661, grad_fn=<MseLossBackward>) tensor(0.5885, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8281, grad_fn=<MseLossBackward>) tensor(0.5766, grad_fn=<MseLossBackward>)\n",
            "tensor(0.7900, grad_fn=<MseLossBackward>) tensor(0.5650, grad_fn=<MseLossBackward>)\n",
            "tensor(0.7539, grad_fn=<MseLossBackward>) tensor(0.5541, grad_fn=<MseLossBackward>)\n",
            "tensor(0.7198, grad_fn=<MseLossBackward>) tensor(0.5433, grad_fn=<MseLossBackward>)\n",
            "tensor(0.6875, grad_fn=<MseLossBackward>) tensor(0.5330, grad_fn=<MseLossBackward>)\n",
            "tensor(0.6553, grad_fn=<MseLossBackward>) tensor(0.5229, grad_fn=<MseLossBackward>)\n",
            "tensor(0.6228, grad_fn=<MseLossBackward>) tensor(0.5130, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5921, grad_fn=<MseLossBackward>) tensor(0.5035, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5633, grad_fn=<MseLossBackward>) tensor(0.4935, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5359, grad_fn=<MseLossBackward>) tensor(0.4833, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5102, grad_fn=<MseLossBackward>) tensor(0.4737, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4871, grad_fn=<MseLossBackward>) tensor(0.4644, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4664, grad_fn=<MseLossBackward>) tensor(0.4552, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4469, grad_fn=<MseLossBackward>) tensor(0.4459, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4287, grad_fn=<MseLossBackward>) tensor(0.4367, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4118, grad_fn=<MseLossBackward>) tensor(0.4278, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3963, grad_fn=<MseLossBackward>) tensor(0.4190, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}