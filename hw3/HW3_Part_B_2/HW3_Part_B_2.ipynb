{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3 - Part B.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgHqdH4gn4vu"
      },
      "source": [
        "import numpy as np\n",
        "def generate_non_linear_three_input_two_output(number_of_rows, dimensions, weights_0, bias_0, weights_1, bias_1):\n",
        "\n",
        "  n = number_of_rows\n",
        "  d = dimensions\n",
        "\n",
        "  # Generate numbers between -1.0 and 1.0, n rows and 3 columns\n",
        "  x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "  # Showing 20 of them\n",
        "  # print(x[:10])\n",
        "\n",
        "  # y = w * x + b\n",
        "  # y = (w_0 * x_0) + (w_1 * x_1) + (w_2 * x_2)\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_0 = np.array([weights_0]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_0 = np.array(bias_0)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_0 = ((x ** 2) @ weights_true_0) + (x @ weights_true_0) + bias_true_0\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_0.shape}, bias: {bias_true_0.shape}, y: {y_true_0.shape}')\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_1 = np.array([weights_1]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_1 = np.array(bias_1)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_1 = ((x ** 2) @ weights_true_1) + (x @ weights_true_1) + bias_true_1\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_1.shape}, bias: {bias_true_1.shape}, y: {y_true_1.shape}')\n",
        "\n",
        "  return { \"input\" : x, \"weights_true_0\" : weights_true_0, \"bias_true_0\" : bias_true_0, \"y_true_0\" : y_true_0, \"weights_true_1\" : weights_true_1, \"bias_true_1\" : bias_true_1, \"y_true_1\" : y_true_1}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI0LY92GtUAq",
        "outputId": "7e461c48-f47b-417f-f4f3-bfe87d6972ab"
      },
      "source": [
        "three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVpZM8XUtC3p"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TorchModel(nn.Module):\n",
        "  def __init__(self, input_dim, num_hidden):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, num_hidden)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(num_hidden, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    l1 = self.linear1(x)\n",
        "    r = self.relu(l1)\n",
        "    l2 = self.linear2(r)\n",
        "    return l2\n",
        "  \n",
        "x = three_input_two_output_func['input']\n",
        "y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_0']).float()]\n",
        "d = 3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqpX4oiwoRB0",
        "outputId": "4692d4ce-8d4f-4f3a-df30-d1b97043403a"
      },
      "source": [
        "# Now we run the training loop\n",
        "from typing import Any, Callable\n",
        "\n",
        "def torch_fit():\n",
        "  \n",
        "  three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])\n",
        "  x = torch.tensor(three_input_two_output_func['input']).float()\n",
        "  y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_1']).float()]\n",
        "  d = 3\n",
        "  \n",
        "  lr = 0.1\n",
        "  num_epochs = 40\n",
        "  \n",
        "  loss_0 = nn.MSELoss()\n",
        "  model_0 = TorchModel(d, 10)\n",
        "\n",
        "  loss_1 = nn.MSELoss()\n",
        "  model_1 = TorchModel(d, 10)\n",
        "\n",
        "  optimizer_0 = torch.optim.SGD(model_0.parameters(), lr=lr)\n",
        "  optimizer_1 = torch.optim.SGD(model_1.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    optimizer_0.zero_grad()\n",
        "    optimizer_1.zero_grad()\n",
        "    \n",
        "    y_pred_tensor_0 = model_0(x)\n",
        "    y_pred_tensor_1 = model_1(x)\n",
        "\n",
        "    loss_value_0 = (y_pred_tensor_0 - y_true_0_1[0]).sum()\n",
        "    loss_value_1 = (y_pred_tensor_1 - y_true_0_1[1]).sum()\n",
        "\n",
        "    print(loss_value_0, loss_value_1)\n",
        "\n",
        "    loss_value_0.backward()\n",
        "    loss_value_1.backward()\n",
        "\n",
        "    optimizer_0.step()\n",
        "    optimizer_1.step()\n",
        "\n",
        "torch_fit()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "tensor(-169.9235, grad_fn=<SumBackward0>) tensor(-297.4117, grad_fn=<SumBackward0>)\n",
            "tensor(-5517.2524, grad_fn=<SumBackward0>) tensor(-7241.6274, grad_fn=<SumBackward0>)\n",
            "tensor(-685213.6875, grad_fn=<SumBackward0>) tensor(-1315988.2500, grad_fn=<SumBackward0>)\n",
            "tensor(-3.3700e+08, grad_fn=<SumBackward0>) tensor(-5.9958e+08, grad_fn=<SumBackward0>)\n",
            "tensor(-1.6259e+11, grad_fn=<SumBackward0>) tensor(-2.7282e+11, grad_fn=<SumBackward0>)\n",
            "tensor(-7.6797e+13, grad_fn=<SumBackward0>) tensor(-1.2341e+14, grad_fn=<SumBackward0>)\n",
            "tensor(-3.5727e+16, grad_fn=<SumBackward0>) tensor(-5.5564e+16, grad_fn=<SumBackward0>)\n",
            "tensor(-1.6436e+19, grad_fn=<SumBackward0>) tensor(-2.4927e+19, grad_fn=<SumBackward0>)\n",
            "tensor(-7.4975e+21, grad_fn=<SumBackward0>) tensor(-1.1150e+22, grad_fn=<SumBackward0>)\n",
            "tensor(-3.3980e+24, grad_fn=<SumBackward0>) tensor(-4.9760e+24, grad_fn=<SumBackward0>)\n",
            "tensor(-1.5323e+27, grad_fn=<SumBackward0>) tensor(-2.2166e+27, grad_fn=<SumBackward0>)\n",
            "tensor(-6.8822e+29, grad_fn=<SumBackward0>) tensor(-9.8591e+29, grad_fn=<SumBackward0>)\n",
            "tensor(-3.0815e+32, grad_fn=<SumBackward0>) tensor(-4.3799e+32, grad_fn=<SumBackward0>)\n",
            "tensor(-1.3763e+35, grad_fn=<SumBackward0>) tensor(-1.9439e+35, grad_fn=<SumBackward0>)\n",
            "tensor(-6.1343e+37, grad_fn=<SumBackward0>) tensor(-8.6203e+37, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(-inf, grad_fn=<SumBackward0>) tensor(-inf, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n",
            "tensor(nan, grad_fn=<SumBackward0>) tensor(nan, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}