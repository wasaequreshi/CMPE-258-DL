{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3 - Part B.3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Igb-G2gkGz"
      },
      "source": [
        "import numpy as np\n",
        "def generate_non_linear_three_input_two_output(number_of_rows, dimensions, weights_0, bias_0, weights_1, bias_1):\n",
        "\n",
        "  n = number_of_rows\n",
        "  d = dimensions\n",
        "\n",
        "  # Generate numbers between -1.0 and 1.0, n rows and 3 columns\n",
        "  x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "  # Showing 20 of them\n",
        "  # print(x[:10])\n",
        "\n",
        "  # y = w * x + b\n",
        "  # y = (w_0 * x_0) + (w_1 * x_1) + (w_2 * x_2)\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_0 = np.array([weights_0]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_0 = np.array(bias_0)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_0 = ((x ** 2) @ weights_true_0) + (x @ weights_true_0) + bias_true_0\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_0.shape}, bias: {bias_true_0.shape}, y: {y_true_0.shape}')\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_1 = np.array([weights_1]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_1 = np.array(bias_1)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_1 = ((x ** 2) @ weights_true_1) + (x @ weights_true_1) + bias_true_1\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_1.shape}, bias: {bias_true_1.shape}, y: {y_true_1.shape}')\n",
        "\n",
        "  return { \"input\" : x, \"weights_true_0\" : weights_true_0, \"bias_true_0\" : bias_true_0, \"y_true_0\" : y_true_0, \"weights_true_1\" : weights_true_1, \"bias_true_1\" : bias_true_1, \"y_true_1\" : y_true_1}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juEQKmHWgptG",
        "outputId": "3177eb98-5d16-4dcc-8a68-e21b7c5acd86"
      },
      "source": [
        "three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwveWyCUjA9p"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "d = 3\n",
        "\n",
        "mlp_0 = nn.Sequential(nn.Linear(d, 1), nn.ReLU())\n",
        "x = torch.tensor(three_input_two_output_func['input']).float()\n",
        "y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_1']).float()]\n",
        "y_pred_0 = mlp_0(x)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l78sDtvygyPf",
        "outputId": "bbaf6d2b-1c2d-47c6-f27e-9b7998384706"
      },
      "source": [
        "# Now we run the training loop\n",
        "from typing import Any, Callable\n",
        "\n",
        "def torch_fit():\n",
        "  \n",
        "  # mlp_0 = nn.Sequential(nn.Linear(d, 1), nn.ReLU())\n",
        "  # x = torch.tensor(three_input_two_output_func['input']).float()\n",
        "  # y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_1']).float()]\n",
        "  # y_pred_0 = mlp_0(x)\n",
        "\n",
        "  three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])\n",
        "  x = torch.tensor(three_input_two_output_func['input']).float()\n",
        "  y_true_0_1 = [torch.tensor(three_input_two_output_func['y_true_0']).float(), torch.tensor(three_input_two_output_func['y_true_1']).float()]\n",
        "  d = 3\n",
        "  n = 1\n",
        "  lr = 0.1\n",
        "  num_epochs = 40\n",
        "  \n",
        "  model_0 = nn.Sequential(nn.Linear(d, n), nn.ReLU(), nn.Linear(n, n))\n",
        "\n",
        "  model_1 = nn.Sequential(nn.Linear(d, n), nn.ReLU(), nn.Linear(n, n))\n",
        "\n",
        "  optimizer_0 = torch.optim.SGD(model_0.parameters(), lr=lr)\n",
        "  optimizer_1 = torch.optim.SGD(model_1.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    optimizer_0.zero_grad()\n",
        "    optimizer_1.zero_grad()\n",
        "    \n",
        "    y_pred_tensor_0 = model_0(x)\n",
        "    y_pred_tensor_1 = model_1(x)\n",
        "\n",
        "    loss_value_0 = (y_pred_tensor_0 - y_true_0_1[0]).sum()\n",
        "    loss_value_1 = (y_pred_tensor_1 - y_true_0_1[1]).sum()\n",
        "\n",
        "    print(loss_value_0, loss_value_1)\n",
        "\n",
        "    loss_value_0.backward()\n",
        "    loss_value_1.backward()\n",
        "\n",
        "    optimizer_0.step()\n",
        "    optimizer_1.step()\n",
        "\n",
        "torch_fit()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "tensor(-147.2466, grad_fn=<SumBackward0>) tensor(-145.4695, grad_fn=<SumBackward0>)\n",
            "tensor(-4210.6650, grad_fn=<SumBackward0>) tensor(-4160.1001, grad_fn=<SumBackward0>)\n",
            "tensor(-8210.6660, grad_fn=<SumBackward0>) tensor(-8160.1001, grad_fn=<SumBackward0>)\n",
            "tensor(-12210.6660, grad_fn=<SumBackward0>) tensor(-12160.1006, grad_fn=<SumBackward0>)\n",
            "tensor(-16210.6660, grad_fn=<SumBackward0>) tensor(-16160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-20210.6660, grad_fn=<SumBackward0>) tensor(-20160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-24210.6680, grad_fn=<SumBackward0>) tensor(-24160.0996, grad_fn=<SumBackward0>)\n",
            "tensor(-28210.6660, grad_fn=<SumBackward0>) tensor(-28160.1035, grad_fn=<SumBackward0>)\n",
            "tensor(-32210.6660, grad_fn=<SumBackward0>) tensor(-32160.1035, grad_fn=<SumBackward0>)\n",
            "tensor(-36210.6680, grad_fn=<SumBackward0>) tensor(-36160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-40210.6680, grad_fn=<SumBackward0>) tensor(-40160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-44210.6680, grad_fn=<SumBackward0>) tensor(-44160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-48210.6680, grad_fn=<SumBackward0>) tensor(-48160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-52210.6680, grad_fn=<SumBackward0>) tensor(-52160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-56210.6680, grad_fn=<SumBackward0>) tensor(-56160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-60210.6680, grad_fn=<SumBackward0>) tensor(-60160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-64210.6680, grad_fn=<SumBackward0>) tensor(-64160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-68210.6719, grad_fn=<SumBackward0>) tensor(-68160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-72210.6719, grad_fn=<SumBackward0>) tensor(-72160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-76210.6641, grad_fn=<SumBackward0>) tensor(-76160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-80210.6641, grad_fn=<SumBackward0>) tensor(-80160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-84210.6641, grad_fn=<SumBackward0>) tensor(-84160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-88210.6719, grad_fn=<SumBackward0>) tensor(-88160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-92210.6719, grad_fn=<SumBackward0>) tensor(-92160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-96210.6719, grad_fn=<SumBackward0>) tensor(-96160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-100210.6719, grad_fn=<SumBackward0>) tensor(-100160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-104210.6719, grad_fn=<SumBackward0>) tensor(-104160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-108210.6719, grad_fn=<SumBackward0>) tensor(-108160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-112210.6719, grad_fn=<SumBackward0>) tensor(-112160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-116210.6719, grad_fn=<SumBackward0>) tensor(-116160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-120210.6641, grad_fn=<SumBackward0>) tensor(-120160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-124210.6641, grad_fn=<SumBackward0>) tensor(-124160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-128210.6641, grad_fn=<SumBackward0>) tensor(-128160.1016, grad_fn=<SumBackward0>)\n",
            "tensor(-132210.6875, grad_fn=<SumBackward0>) tensor(-132160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-136210.6875, grad_fn=<SumBackward0>) tensor(-136160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-140210.6875, grad_fn=<SumBackward0>) tensor(-140160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-144210.6875, grad_fn=<SumBackward0>) tensor(-144160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-148210.6875, grad_fn=<SumBackward0>) tensor(-148160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-152210.6875, grad_fn=<SumBackward0>) tensor(-152160.1094, grad_fn=<SumBackward0>)\n",
            "tensor(-156210.6875, grad_fn=<SumBackward0>) tensor(-156160.1094, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}