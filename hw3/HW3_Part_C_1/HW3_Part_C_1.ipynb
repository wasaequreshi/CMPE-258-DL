{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3 - Part C.1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_6MClQlgk8N"
      },
      "source": [
        "import numpy as np\n",
        "def generate_non_linear_three_input_two_output(number_of_rows, dimensions, weights_0, bias_0, weights_1, bias_1):\n",
        "\n",
        "  n = number_of_rows\n",
        "  d = dimensions\n",
        "\n",
        "  # Generate numbers between -1.0 and 1.0, n rows and 3 columns\n",
        "  x = np.random.uniform(-1, 1, (n, d))\n",
        "\n",
        "  # Showing 20 of them\n",
        "  # print(x[:10])\n",
        "\n",
        "  # y = w * x + b\n",
        "  # y = (w_0 * x_0) + (w_1 * x_1) + (w_2 * x_2)\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_0 = np.array([weights_0]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_0 = np.array(bias_0)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_0 = ((x ** 2) @ weights_true_0) + (x @ weights_true_0) + bias_true_0\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_0.shape}, bias: {bias_true_0.shape}, y: {y_true_0.shape}')\n",
        "\n",
        "  # Randomly assigning weights\n",
        "  weights_true_1 = np.array([weights_1]).T\n",
        "\n",
        "  # print(weights_true)\n",
        "\n",
        "  bias_true_1 = np.array(bias_1)\n",
        "  # print(bias_true)\n",
        "\n",
        "  # print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "  # Matmult with data and wieghts, adding bias_true as well.\n",
        "  y_true_1 = ((x ** 2) @ weights_true_1) + (x @ weights_true_1) + bias_true_1\n",
        "  # print(y_true[:10])\n",
        "\n",
        "  print (f'x: {x.shape}, weights: {weights_true_1.shape}, bias: {bias_true_1.shape}, y: {y_true_1.shape}')\n",
        "\n",
        "  return { \"input\" : x, \"weights_true_0\" : weights_true_0, \"bias_true_0\" : bias_true_0, \"y_true_0\" : y_true_0, \"weights_true_1\" : weights_true_1, \"bias_true_1\" : bias_true_1, \"y_true_1\" : y_true_1}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CByfjY2kjFgI",
        "outputId": "ae35ec18-aca5-490e-9336-174f1d1797c5"
      },
      "source": [
        "three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn2tNjMgDJN1"
      },
      "source": [
        "# Now we run the training loop\n",
        "from typing import Any, Callable\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "class Linear(keras.layers.Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "\n",
        "  def __init__(self, units=1):\n",
        "      super(Linear, self).__init__()\n",
        "      self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.input_size = input_shape[1]\n",
        "      self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "      self.b = self.add_weight(shape=(self.units,),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "     \n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "\n",
        "# Let's reuse the Linear class\n",
        "# with a `build` method that we defined above.\n",
        "\n",
        "class MLP(keras.layers.Layer):\n",
        "    \"\"\"Simple stack of Linear layers.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear_1 = Linear()\n",
        "        self.linear_2 = Linear()\n",
        "        self.linear_3 = Linear()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return self.linear_3(x)\n",
        "\n",
        "class ActivityRegularization(keras.layers.Layer):\n",
        "  \"\"\"Layer that creates an activity sparsity regularization loss.\"\"\"\n",
        "  \n",
        "  def __init__(self, rate=1e-2):\n",
        "    super(ActivityRegularization, self).__init__()\n",
        "    self.rate = rate\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # We use `add_loss` to create a regularization loss\n",
        "    # that depends on the inputs.\n",
        "    self.add_loss(self.rate * tf.reduce_sum(inputs))\n",
        "    return inputs\n",
        "\n",
        "class SparseMLP(keras.layers.Layer):\n",
        "  \"\"\"Stack of Linear layers with a sparsity regularization loss.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "      super(SparseMLP, self).__init__()\n",
        "      self.linear_1 = Linear(1)\n",
        "      self.regularization = ActivityRegularization(1e-2)\n",
        "      self.linear_3 = Linear(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.linear_1(inputs)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.regularization(x)\n",
        "      return self.linear_3(x)\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDv55UkBjHv5",
        "outputId": "4ed0dd93-d113-4cbf-ae0b-b96f302bd4d8"
      },
      "source": [
        "# Now we run the training loop\n",
        "from typing import Any, Callable\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "def tensorfit():\n",
        "  \n",
        "  three_input_two_output_func = generate_non_linear_three_input_two_output(200, 3, [3, -2, 1], [.2], [2, -1, 3], [.4])\n",
        "  x = tf.convert_to_tensor(three_input_two_output_func['input'])\n",
        "  y_true_0_1 = [tf.convert_to_tensor(three_input_two_output_func['y_true_0']), tf.convert_to_tensor(three_input_two_output_func['y_true_1'])]\n",
        "  d = 3\n",
        "  \n",
        "  lr = 0.1\n",
        "  num_epochs = 40\n",
        "  \n",
        "  loss_0 = tf.keras.losses.MeanSquaredError()\n",
        "  model_0 = SparseMLP()\n",
        "\n",
        "  loss_1 = tf.keras.losses.MeanSquaredError()\n",
        "  model_1 = SparseMLP()\n",
        "\n",
        "  optimizer_0 = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "  optimizer_1 = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred_tensor_0 = model_0(x)\n",
        "      loss_value_0 = loss_0(y_pred_tensor_0, y_true_0_1[0])\n",
        "      loss_value_0 = tf.cast(loss_value_0, tf.float32, name=None)\n",
        "      loss_value_0 += sum(model_0.losses)\n",
        "      gradients_0 = tape.gradient(loss_value_0, model_0.trainable_weights)\n",
        "      optimizer_0.apply_gradients(zip(gradients_0, model_0.trainable_weights))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred_tensor_1 = model_1(x)\n",
        "      loss_value_1 = loss_1(y_pred_tensor_1, y_true_0_1[1])\n",
        "      loss_value_1 = tf.cast(loss_value_1, tf.float32, name=None)\n",
        "      loss_value_1 += sum(model_1.losses)\n",
        "      gradients_1 = tape.gradient(loss_value_1, model_1.trainable_weights)\n",
        "      optimizer_1.apply_gradients(zip(gradients_1, model_1.trainable_weights))      \n",
        "      \n",
        "    print(loss_value_0, loss_value_1)\n",
        "\n",
        "\n",
        "tensorfit()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "x: (200, 3), weights: (3, 1), bias: (1,), y: (200, 1)\n",
            "tf.Tensor(5.888475, shape=(), dtype=float32) tf.Tensor(8.5227585, shape=(), dtype=float32)\n",
            "tf.Tensor(5.586216, shape=(), dtype=float32) tf.Tensor(7.3731966, shape=(), dtype=float32)\n",
            "tf.Tensor(5.425371, shape=(), dtype=float32) tf.Tensor(6.716572, shape=(), dtype=float32)\n",
            "tf.Tensor(5.3224306, shape=(), dtype=float32) tf.Tensor(6.296332, shape=(), dtype=float32)\n",
            "tf.Tensor(5.256548, shape=(), dtype=float32) tf.Tensor(6.027378, shape=(), dtype=float32)\n",
            "tf.Tensor(5.2143836, shape=(), dtype=float32) tf.Tensor(5.855248, shape=(), dtype=float32)\n",
            "tf.Tensor(5.187398, shape=(), dtype=float32) tf.Tensor(5.745084, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1701274, shape=(), dtype=float32) tf.Tensor(5.67458, shape=(), dtype=float32)\n",
            "tf.Tensor(5.159075, shape=(), dtype=float32) tf.Tensor(5.629457, shape=(), dtype=float32)\n",
            "tf.Tensor(5.152001, shape=(), dtype=float32) tf.Tensor(5.600578, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1474733, shape=(), dtype=float32) tf.Tensor(5.582096, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1445756, shape=(), dtype=float32) tf.Tensor(5.5702667, shape=(), dtype=float32)\n",
            "tf.Tensor(5.142721, shape=(), dtype=float32) tf.Tensor(5.562696, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1415343, shape=(), dtype=float32) tf.Tensor(5.557852, shape=(), dtype=float32)\n",
            "tf.Tensor(5.140775, shape=(), dtype=float32) tf.Tensor(5.554751, shape=(), dtype=float32)\n",
            "tf.Tensor(5.140289, shape=(), dtype=float32) tf.Tensor(5.5527663, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1399775, shape=(), dtype=float32) tf.Tensor(5.551496, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1397786, shape=(), dtype=float32) tf.Tensor(5.5506835, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1396513, shape=(), dtype=float32) tf.Tensor(5.5501637, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1395698, shape=(), dtype=float32) tf.Tensor(5.5498304, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1395173, shape=(), dtype=float32) tf.Tensor(5.549617, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394835, shape=(), dtype=float32) tf.Tensor(5.5494804, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394625, shape=(), dtype=float32) tf.Tensor(5.549393, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394486, shape=(), dtype=float32) tf.Tensor(5.549338, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394396, shape=(), dtype=float32) tf.Tensor(5.5493016, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394343, shape=(), dtype=float32) tf.Tensor(5.549279, shape=(), dtype=float32)\n",
            "tf.Tensor(5.139431, shape=(), dtype=float32) tf.Tensor(5.549264, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394286, shape=(), dtype=float32) tf.Tensor(5.5492554, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394267, shape=(), dtype=float32) tf.Tensor(5.5492487, shape=(), dtype=float32)\n",
            "tf.Tensor(5.139426, shape=(), dtype=float32) tf.Tensor(5.549245, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.549242, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.5492406, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.5492396, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.5492396, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394243, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394243, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394243, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394253, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n",
            "tf.Tensor(5.1394243, shape=(), dtype=float32) tf.Tensor(5.549238, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}