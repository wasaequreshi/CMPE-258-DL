# Submission Information

Every extra credit was done

## Part a

This is the code that I followed: https://github.com/lmoroney/tfbook/tree/master/chapter18/RockPaperScissors

It was a copy and paste exercise but instead I commented the code and looked up what each part of the code meant to get a better understanding of how this was done. The webcam.js and retrain.html I left with no comments. The webcam.js was provided and the HTML didn't need any obvious comments.

Also this is a functioning app. I was able to open the retrain.html file and test this out. I only added 3 images of me doing rock, paper, and scissors. It was able to accurately identify what I was choosing.

## Part b

This was also using this guide: https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/rnn.ipynb#scrollTo=a5617759e54e

I read through the article and followed the steps. Reading the colab is not enough however, side reading is needed to understand the different RNN models.

## Part c

This was also using this guide: https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android#0

I read through the article and followed the steps. I ran the colab to get the tflite model (added that as well under TFLClassify-main/start/ml) I then made the respective changes in the MainActivity.kt file. I was not able to run this on my machine however (M1 Mac, I think some issues with the new processor) and mimiced every step. I followed the steps and theoretically this should work on your machine upon running :)

## Part d
This was also using this guide: https://codelabs.developers.google.com/codelabs/tensorflowjs-object-detection#8

I followed the code and step for this. This is actually quite amazing. I tested this and it was detecting me and the fridge that was behind me. This you can test without setting up android studio.

## Part e
This was also using this guide: https://colab.research.google.com/drive/1Gxr8IbHrC8HnZ2sQ0ukeJxhYAGR_3B9u

I copied the colab and followed the steps. I ran the whole thing (this took a while to finish running) and checked each step (similar steps for our final project). Since finishing my studying for my final, I know that RNN's would be really good for this (and this is what they use in the colab with a mix of CNN). They did single step models and multi step models and compared the different models. I can't really implement this from scratch but hopefully running the steps and reading through this will suffice for some credit. Interesting research and implementation for forecasting on climate.

## Conclusion
I really liked part a and part d. The output and results were really fun and used my laptop webcam. The android one I didn't get to test myself but looks like it would be just as fun. I will probably run that on a intel based machine and see if that works to test the tflite mode. I also had the limitation of running the app since I do not have an android device. I can get around that with an emulator however (but that really slows down the PC and hits the fans!).